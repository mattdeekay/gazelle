{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Deprecated code\\nimport pickle   # data\\nimport sys      # directories\\nsys.path.append(\"code\") # contains CNN model\\nfrom gazelle_utils import *\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Deprecated code\n",
    "import pickle   # data\n",
    "import sys      # directories\n",
    "sys.path.append(\"code\") # contains CNN model\n",
    "from gazelle_utils import *\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Is this Owen's instance or Matthew's?\n",
    "#### CHANGE THE VARIABLE RIGHT HERE ####\n",
    "instance = 'matthew'   # 'matthew' or 'owen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  8  files:  ['XYArray1.npy', 'XYArray2.npy', 'XYArray3.npy', 'XYArray4.npy', 'data1.npy', 'data2.npy', 'data3.npy', 'data4.npy']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "if (instance == 'matthew'):\n",
    "    datapath = \"data_CNN/clean\"\n",
    "else:\n",
    "    datapath = \"../../Owen/gazelle-github-Owen/data_CNN/clean\"\n",
    "onlyfiles = [f for f in listdir(datapath) if isfile(join(datapath, f))]\n",
    "onlyfiles.sort()\n",
    "print \"There are \", len(onlyfiles), \" files: \", onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "fileNums = []\n",
    "for f in onlyfiles:\n",
    "    fileNums.append(int(re.sub(\"[^0-9]\", \"\", f)))\n",
    "fileNums = list(set(fileNums))\n",
    "print fileNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an odd number of files. Look back at data folder.\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "if len(onlyfiles) % 3 is not 0: \n",
    "    print \"There is an odd number of files. Look back at data folder.\"\n",
    "else:\n",
    "    print \"Good to go.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def load_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        return np.load(f)\n",
    "\n",
    "def load_all(ROOT, fileno):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    f = os.path.join(ROOT, 'data%d.npy' % (fileno, ))\n",
    "    g = os.path.join(ROOT, 'XYArray%d.npy' % (fileno, ))\n",
    "    X = load_batch(f)\n",
    "    Y = load_batch(g)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)    \n",
    "    Xall = np.concatenate(xs)\n",
    "    yall = np.concatenate(ys)\n",
    "    print \"Xall shape: \", Xall.shape\n",
    "    print \"yall shape: \", yall.shape\n",
    "    del X, Y\n",
    "    return Xall, yall\n",
    "\n",
    "\n",
    "def get_and_segment_data(fileno, subtract_mean=False, directory = \"data_CNN/clean\", train_cut = 0.7,\n",
    "                    val_cut = 0.2, test_cut = 0.1):\n",
    "    \"\"\"\n",
    "    Load the dataset from disk and maybe perform preprocessing to prepare\n",
    "    it for classifiers. These are the same steps as we used for the SVM, but\n",
    "    condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw data\n",
    "    X_all, y_all = load_all(directory, fileno)\n",
    "    \n",
    "    # Slicing the data\n",
    "    num_training = int(X_all.shape[0] * train_cut)\n",
    "    num_validation = int(X_all.shape[0] * val_cut)\n",
    "    num_testing = int(X_all.shape[0] * test_cut)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_all[mask]\n",
    "    y_train = y_all[mask]\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_all[mask]\n",
    "    y_val = y_all[mask]\n",
    "    mask = list(range(num_training + num_validation, num_training + num_validation + num_testing))\n",
    "    X_test = X_all[mask]\n",
    "    y_test = y_all[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    if subtract_mean:\n",
    "        mean_image = np.mean(X_train, axis=0)\n",
    "        X_train -= mean_image\n",
    "        X_val -= mean_image\n",
    "        X_test -= mean_image\n",
    "\n",
    "    return X_train.astype('float32'), y_train.astype('float32'), X_val.astype('float32'), y_val.astype('float32'), X_test.astype('float32'), y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 144, 144, 3, 4])\n",
    "y = tf.placeholder(tf.float32, [None, 2])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def cnn_model_fn(features, labels):\n",
    "    # features = Tensor(\"Print:0\", shape=(?, 144, 144, 3, 4), dtype=float32)\n",
    "\n",
    "    # GC Input Layer\n",
    "    # we have 4 inputs in the order: right eye, left eye, face, face grid (bound by dim #4 of value 4)\n",
    "    #   Each one is [batch_size, width, height, channels] = num_batches x 144 x 144 x 3.\n",
    "\n",
    "    R_eye = tf.squeeze(tf.slice(features, [0,0,0,0,0], [-1, 144, 144, 3, 1]), axis=4)\n",
    "    L_eye = tf.squeeze(tf.slice(features, [0,0,0,0,1], [-1, 144, 144, 3, 1]), axis=4)\n",
    "    face  = tf.squeeze(tf.slice(features, [0,0,0,0,2], [-1, 144, 144, 3, 1]), axis=4)\n",
    "    fgrid = tf.squeeze(tf.slice(features, [0,0,0,0,3], [-1, 144, 144, 3, 1]), axis=4)\n",
    "    # Tensor(\"Print_1:0\", shape=(?, 1, 144, 144, 3), dtype=float32)\n",
    "\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Input Tensor Shape: [batch_size, 144, 144, 3]\n",
    "    # Output Tensor Shape: [batch_size, 144, 144, 96]\n",
    "    conv_ER1 = tf.layers.conv2d(\n",
    "      inputs=R_eye,\n",
    "      filters=96,\n",
    "      kernel_size=[11,11],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    conv_EL1 = tf.layers.conv2d(\n",
    "      inputs=L_eye,\n",
    "      filters=96,\n",
    "      kernel_size=[11,11],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    conv_F1  = tf.layers.conv2d(\n",
    "      inputs=face,\n",
    "      filters=96,\n",
    "      kernel_size=[11,11],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    # Tensor(\"Print:0\", shape=(?, 144, 144, 96), dtype=float32)\n",
    "\n",
    "\n",
    "    # Pooling Layer 1\n",
    "    # Input Tensor Shape: [batch_size, 144, 144, 96]\n",
    "    # Output Tensor Shape: [batch_size, 72, 72, 96]\n",
    "    conv_ER1_pooled = tf.layers.max_pooling2d(\n",
    "      inputs=conv_ER1,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "    conv_EL1_pooled = tf.layers.max_pooling2d(\n",
    "      inputs=conv_EL1,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "    conv_F1_pooled = tf.layers.max_pooling2d(\n",
    "      inputs=conv_F1,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Input Tensor Shape: [batch_size, 72, 72, 96]\n",
    "    # Output Tensor Shape: [batch_size, 72, 72, 256]\n",
    "    conv_ER2 = tf.layers.conv2d(\n",
    "      inputs=conv_ER1_pooled,\n",
    "      filters=256,\n",
    "      kernel_size=[5,5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    conv_EL2 = tf.layers.conv2d(\n",
    "      inputs=conv_EL1_pooled,\n",
    "      filters=256,\n",
    "      kernel_size=[5,5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    conv_F2  = tf.layers.conv2d(\n",
    "      inputs=conv_F1_pooled,\n",
    "      filters=256,\n",
    "      kernel_size=[5,5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Convolutional Layer #3\n",
    "    # Input Tensor Shape: [batch_size, 72, 72, 256]\n",
    "    # Output Tensor Shape: [batch_size, 72, 72, 384]\n",
    "    conv_ER3 = tf.layers.conv2d(\n",
    "      inputs=conv_ER2,\n",
    "      filters=384,\n",
    "      kernel_size=[3,3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    conv_EL3 = tf.layers.conv2d(\n",
    "      inputs=conv_EL2,\n",
    "      filters=384,\n",
    "      kernel_size=[3,3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    conv_F3  = tf.layers.conv2d(\n",
    "      inputs=conv_F2,\n",
    "      filters=384,\n",
    "      kernel_size=[3,3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer 2\n",
    "    # Input Tensor Shape: [batch_size, 72, 72, 384]\n",
    "    # Output Tensor Shape: [batch_size, 36, 36, 384]\n",
    "    conv_ER3_pooled = tf.layers.max_pooling2d(\n",
    "      inputs=conv_ER3,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "    conv_EL3_pooled = tf.layers.max_pooling2d(\n",
    "      inputs=conv_EL3,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "    conv_F3_pooled  = tf.layers.max_pooling2d(\n",
    "      inputs=conv_F3,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "\n",
    "\n",
    "    # Convolutional Layer #4\n",
    "    # Input Tensor Shape: [batch_size, 36, 36, 384]\n",
    "    # Output Tensor Shape: [batch_size, 36, 36, 64]\n",
    "    conv_ER4 = tf.layers.conv2d(\n",
    "      inputs=conv_ER3_pooled,\n",
    "      filters=64,\n",
    "      kernel_size=[1,1],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    conv_EL4 = tf.layers.conv2d(\n",
    "      inputs=conv_EL3_pooled,\n",
    "      filters=64,\n",
    "      kernel_size=[1,1],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    conv_F4  = tf.layers.conv2d(\n",
    "      inputs=conv_F3_pooled,\n",
    "      filters=64,\n",
    "      kernel_size=[1,1],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "    # ----------------------------------\n",
    "\n",
    "    # Dense Layers: Eyes\n",
    "    # Flatten tensors into a batch of vectors, then feed to dense layer\n",
    "    # For each (of the 2 eyes):\n",
    "    #   Input Tensor Shape (flatten): [batch_size, 36, 36, 64]\n",
    "    #   Output Tensor Shape (flatten): [batch_size, 36 * 36 * 64]\n",
    "    # Concatenate:\n",
    "    #   Final Output Tensor Shape: [batch_size, 36 * 36 * 64 * 2]\n",
    "\n",
    "    # Dense Layer Eyes: 128 units\n",
    "    ER_flat = tf.reshape(conv_ER4, [-1, 36 * 36 * 64])\n",
    "    EL_flat = tf.reshape(conv_EL4, [-1, 36 * 36 * 64])\n",
    "    eye_flat = tf.concat([ER_flat, EL_flat], axis=1)\n",
    "    dense_eyes = tf.layers.dense(inputs=eye_flat, units=128, activation=tf.nn.relu)\n",
    "\n",
    "    # Dense Layers: Face. 128, 64\n",
    "    F_flat = tf.reshape(conv_F4, [-1, 36 * 36 * 64])\n",
    "    # Dense Layer Face 1: 128 units\n",
    "    dense_face1 = tf.layers.dense(inputs=F_flat, units=128, activation=tf.nn.relu)\n",
    "    # Dense Layer Face 2: 64 units\n",
    "    dense_face2 = tf.layers.dense(inputs=dense_face1, units=64, activation=tf.nn.relu)\n",
    "\n",
    "    # Dense Layers: Face Grid boolean mask\n",
    "    #   Post-pooling Tensor SHape: [batch_size, 72, 72]\n",
    "    fgrid_mask = tf.slice(fgrid, [0,0,0,0], [-1, 144, 144, 1])\n",
    "    fgrid_pooled = tf.layers.max_pooling2d(\n",
    "      inputs=fgrid_mask,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "    fgrid_flat = tf.reshape(fgrid_pooled, [-1, 72 * 72])\n",
    "    # Dense Layer Face-grid 1: 256 units\n",
    "    dense_fgrid1 = tf.layers.dense(inputs=fgrid_flat, units=128, activation=tf.nn.relu)\n",
    "    # Dense Layer Face-grid 1: 128 units\n",
    "    dense_fgrid2 = tf.layers.dense(inputs=dense_fgrid1, units=64, activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "    # Final Dense Layers\n",
    "    #   concatenate tensors: eyes, face, face-grid.\n",
    "    combined_flat = tf.concat([dense_eyes, dense_face2, dense_fgrid2], axis=1) # shape [batch_size, 128 + 64 + 64]\n",
    "    dense_final = tf.layers.dense(inputs=combined_flat, units=128, activation=tf.nn.relu)\n",
    "    xy_output = tf.layers.dense(inputs=dense_final, units=2)\n",
    "    return xy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy_output = cnn_model_fn(X,y)\n",
    "error = tf.sqrt(tf.losses.mean_squared_error(labels=y, predictions=xy_output))\n",
    "\n",
    "# define our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(1e-5) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "num_batches:  4\n",
      "Xall shape:  (1832, 144, 144, 3, 4)\n",
      "yall shape:  (1832, 2)\n",
      "We got to here"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def show_images(images):\n",
    "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return\n",
    "'''\n",
    "\n",
    "def run_model(session, predict, loss_val, files, num_batches,\n",
    "              epochs=1, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    # have tensorflow compute accuracy\n",
    "    #correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    #error = tf.sqrt(tf.losses.mean_squared_error(labels=labels, predictions=xy_output))\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    # LATER train_indicies = np.arange(Xd.shape[0])\n",
    "    # LATER np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [loss_val]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    print \"num_batches: \", num_batches\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        numImages = 0\n",
    "        errors = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(num_batches):\n",
    "            # generate indicies for the batch\n",
    "            #start_idx = (i*batch_size)%X_train.shape[0]\n",
    "            #idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            X_train, y_train, X_val, y_val, _, _ = get_and_segment_data(i+1)\n",
    "            print \"We got to here\"\n",
    "            print \"X_train: \", X_train.shape\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: X_train,\n",
    "                         y: y_train,\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = y_train.shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            error, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            errors.append(error*actual_batch_size)\n",
    "            numImages += actual_batch_size\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training error = {1:.3g} and average error of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,error,np.sum(errors)/actual_batch_size))\n",
    "        print \"We have processed \", numImages, \" images.\"\n",
    "        total_loss = np.sum(errors)/numImages\n",
    "        print(\"Epoch {1}, Overall loss = {0:.3g}\".format(total_loss,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(errors)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    return total_loss\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Training')\n",
    "        run_model(sess,xy_output,error,onlyfiles,len(onlyfiles)/2,10,100,train_step,True)\n",
    "        #print('Validation')\n",
    "        #run_model(sess,y_out,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with get_session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    run_model(sess,G_train_step,G_loss,D_train_step,D_loss,G_extra_step,D_extra_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'matching_filenames_23:0' shape=<unknown> dtype=string_ref>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "files = tf.train.match_filenames_once(\"./data_CNN/data*.npy\")\n",
    "print files\n",
    "FIFOdata = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(\"./data_CNN/data*.npy\"), num_epochs=num_epochs)\n",
    "FIFOlabels = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(\"./data_CNN/XYArray*.npy\"), num_epochs=num_epochs)\n",
    "print FIFOdata.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value matching_filenames_28\n\t [[Node: _send_matching_filenames_28_0 = _Send[T=DT_STRING, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=4826793861428859587, tensor_name=\"matching_filenames_28:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](matching_filenames_28)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-4bf152e5e8d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value matching_filenames_28\n\t [[Node: _send_matching_filenames_28_0 = _Send[T=DT_STRING, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=4826793861428859587, tensor_name=\"matching_filenames_28:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](matching_filenames_28)]]"
     ]
    }
   ],
   "source": [
    "files = tf.train.match_filenames_once(\"data_CNN/data*.npy\")\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print (sess.run(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': None, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4295aec6d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': None, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4295aec6d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"CNN_code\")\n",
    "from gazecapture_cnn import cnn_model_fn\n",
    "\n",
    "# Create the Estimator\n",
    "gazelle_estimator = learn.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"tmp/gazelle_conv_model\")\n",
    "# Set up logging for when the CNN trains\n",
    "tensors_to_log = { \"loss\": \"loss_tensor\",\n",
    "                 \"x diff\": \"xdiff_tensor\",\n",
    "                 \"y diff\": \"ydiff_tensor\" } \n",
    "# Need to DEBUG: check that x diff and y diff are logging right.\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log,\n",
    "  every_n_iter=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xall shape:  (1832, 144, 144, 3, 4)\n",
      "yall shape:  (1832, 2)\n",
      "('Train data shape: ', (1282, 144, 144, 3, 4), dtype('float32'))\n",
      "('Train labels shape: ', (1282, 2), dtype('float32'))\n",
      "('Validation data shape: ', (366, 144, 144, 3, 4), dtype('float32'))\n",
      "('Validation labels shape: ', (366, 2), dtype('float32'))\n",
      "('Test data shape: ', (183, 144, 144, 3, 4), dtype('float32'))\n",
      "('Test labels shape: ', (183, 2), dtype('float32'))\n"
     ]
    }
   ],
   "source": [
    "numFiles = len(onlyfiles) / 2 \n",
    "fileno = 1\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_and_segment_data(fileno)\n",
    "print('Train data shape: ', X_train.shape, X_train.dtype)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape, X_val.dtype)\n",
    "print('Validation labels shape: ', y_val.shape, y_val.dtype)\n",
    "print('Test data shape: ', X_test.shape, X_test.dtype)\n",
    "print('Test labels shape: ', y_test.shape, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train data shape: ', (24, 144, 144, 3, 4), dtype('float32'))\n",
      "('Train labels shape: ', (24, 2), dtype('float32'))\n",
      "('Validation data shape: ', (3, 144, 144, 3, 4), dtype('float32'))\n",
      "('Validation labels shape: ', (3, 2), dtype('float32'))\n"
     ]
    }
   ],
   "source": [
    "CNN_DATA_ROOT = \"toy_CNN_data/\"\n",
    "train_data_file = open(CNN_DATA_ROOT + 'train_data_tiny.pkl', 'rb') #batchA size N=364. shape [N, 144,144,3,4]\n",
    "train_labels_file = open(CNN_DATA_ROOT + 'train_labels_tiny.pkl', 'rb')\n",
    "eval_data_file = open(CNN_DATA_ROOT + 'eval_data_tiny.pkl', 'rb') # WRONG testing data, this is in pixels. Trained on cm.\n",
    "eval_labels_file = open(CNN_DATA_ROOT + 'eval_labels_tiny.pkl', 'rb')\n",
    "\n",
    "train_data = pickle.load(train_data_file).astype('float32') #numpy arrays\n",
    "train_labels = pickle.load(train_labels_file).astype('float32')\n",
    "eval_data = pickle.load(eval_data_file).astype('float32')\n",
    "eval_labels = pickle.load(eval_labels_file).astype('float32')\n",
    "\n",
    "print('Train data shape: ', train_data.shape, train_data.dtype)\n",
    "print('Train labels shape: ', train_labels.shape, train_labels.dtype)\n",
    "print('Validation data shape: ', eval_data.shape, eval_data.dtype)\n",
    "print('Validation labels shape: ', eval_labels.shape, eval_labels.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-3de04a4d7bb3>:7: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-3de04a4d7bb3>:7: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-3de04a4d7bb3>:7: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-3de04a4d7bb3>:7: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-3de04a4d7bb3>:7: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-3de04a4d7bb3>:7: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/gazelle_conv_model/model.ckpt-108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/gazelle_conv_model/model.ckpt-108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 109 into tmp/gazelle_conv_model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 109 into tmp/gazelle_conv_model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 106.017, step = 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 106.017, step = 109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 147 into tmp/gazelle_conv_model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 147 into tmp/gazelle_conv_model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 185 into tmp/gazelle_conv_model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 185 into tmp/gazelle_conv_model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 208 into tmp/gazelle_conv_model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 208 into tmp/gazelle_conv_model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 113.756.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 113.756.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Estimator(params=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "gazelle_estimator.fit(\n",
    "  x=X_train,\n",
    "  y=y_train,\n",
    "  batch_size=4,\n",
    "  steps=100, # At every step, does it randomly pull out 4 samples from the 364? Can test this tomorrow\n",
    "  monitors=[logging_hook])\n",
    "\n",
    "# Make our own GC accuracy metric\n",
    "# Configure the accuracy metric for evaluation\n",
    "metrics = {\n",
    "  \"Gazelle prediction mean abs. error\":\n",
    "      learn.MetricSpec(\n",
    "          metric_fn=tf.metrics.mean_absolute_error, prediction_key=\"coords delta\")\n",
    "}\n",
    "\n",
    "# Evaluate the model and print results\n",
    "eval_results = gazelle_estimator.evaluate(\n",
    "  x=eval_data, y=eval_labels, metrics=metrics)\n",
    "print(eval_results)\n",
    "\n",
    "# Very jank way to touch a file, so that if we come back to instance-1 and check the dir,\n",
    "#   we can tell the CNN finished.\n",
    "f = open(\"we-are-finished.txt\", 'w')\n",
    "localtime = time.localtime(time.time())\n",
    "f.write(time.asctime(localtime) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss,correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%X_train.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[i:i+batch_size].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    return total_loss,total_correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Training')\n",
    "        run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will create a simple model to test our understanding of inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 144, 144, 3, 4])\n",
    "y = tf.placeholder(tf.int64, [None, 2])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def faceonly_model(X,labels):\n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    features = tf.cast(X, tf.float32)\n",
    "    # GC Input Layer\n",
    "    # we have 4 inputs in the order: right eye, left eye, face, face grid (bound by dim #4 of value 4)\n",
    "    #   Each one is [batch_size, width, height, channels] = num_batches x 144 x 144 x 3.\n",
    "\n",
    "    R_eye = tf.squeeze(tf.slice(features, [0,0,0,0,0], [-1, 144, 144, 3, 1]), axis=4)\n",
    "    L_eye = tf.squeeze(tf.slice(features, [0,0,0,0,1], [-1, 144, 144, 3, 1]), axis=4)\n",
    "    face  = tf.squeeze(tf.slice(features, [0,0,0,0,2], [-1, 144, 144, 3, 1]), axis=4)\n",
    "    fgrid = tf.squeeze(tf.slice(features, [0,0,0,0,3], [-1, 144, 144, 3, 1]), axis=4)\n",
    "    \n",
    "    conv_F1  = tf.layers.conv2d(\n",
    "      inputs=face,\n",
    "      filters=96,\n",
    "      kernel_size=[11,11],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    conv_F1_pooled = tf.layers.max_pooling2d(\n",
    "      inputs=conv_F1,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "    \n",
    "    conv_F2  = tf.layers.conv2d(\n",
    "      inputs=conv_F1_pooled,\n",
    "      filters=256,\n",
    "      kernel_size=[5,5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    conv_F3  = tf.layers.conv2d(\n",
    "      inputs=conv_F2,\n",
    "      filters=384,\n",
    "      kernel_size=[3,3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    conv_F3_pooled  = tf.layers.max_pooling2d(\n",
    "      inputs=conv_F3,\n",
    "      pool_size=[2,2],\n",
    "      strides=2)\n",
    "\n",
    "    conv_F4  = tf.layers.conv2d(\n",
    "      inputs=conv_F3_pooled,\n",
    "      filters=64,\n",
    "      kernel_size=[1,1],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    # Dense Layers: Face. 128, 64\n",
    "    F_flat = tf.reshape(conv_F4, [-1, 36 * 36 * 64])\n",
    "    # Dense Layer Face 1: 128 units\n",
    "    dense_face1 = tf.layers.dense(inputs=F_flat, units=128, activation=tf.nn.relu)\n",
    "    # Dense Layer Face 2: 64 units\n",
    "    dense_final = tf.layers.dense(inputs=dense_face1, units=64, activation=tf.nn.relu)\n",
    "    \n",
    "    xy_output = tf.layers.dense(inputs=dense_final, units=2)\n",
    "    \n",
    "    return xy_output\n",
    "\n",
    "xy_output = faceonly_model(X,y)\n",
    "\n",
    "# define our loss\n",
    "mean_loss = tf.losses.mean_squared_error(labels=y, predictions=xy_output)\n",
    "\n",
    "# define our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(5e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [3] vs. [3,2]\n\t [[Node: Equal_1 = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ArgMax_1, _recv_Placeholder_1_0)]]\n\nCaused by op u'Equal_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/mdkim/assignment1/.env/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-fe707c067b3f>\", line 69, in <module>\n    run_model(sess,xy_output,mean_loss,X_train,y_train,1,3,3,train_step,True)\n  File \"<ipython-input-18-fe707c067b3f>\", line 5, in run_model\n    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 672, in equal\n    result = _op_def_lib.apply_op(\"Equal\", x=x, y=y, name=name)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [3] vs. [3,2]\n\t [[Node: Equal_1 = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ArgMax_1, _recv_Placeholder_1_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fe707c067b3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxy_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-fe707c067b3f>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(session, predict, loss_val, Xd, yd, epochs, batch_size, print_every, training, plot_losses)\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m# have tensorflow compute loss and correct predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;31m# and (if given) perform a training step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# aggregate performance stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [3] vs. [3,2]\n\t [[Node: Equal_1 = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ArgMax_1, _recv_Placeholder_1_0)]]\n\nCaused by op u'Equal_1', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/mdkim/assignment1/.env/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-fe707c067b3f>\", line 69, in <module>\n    run_model(sess,xy_output,mean_loss,X_train,y_train,1,3,3,train_step,True)\n  File \"<ipython-input-18-fe707c067b3f>\", line 5, in run_model\n    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 672, in equal\n    result = _op_def_lib.apply_op(\"Equal\", x=x, y=y, name=name)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/mdkim/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [3] vs. [3,2]\n\t [[Node: Equal_1 = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ArgMax_1, _recv_Placeholder_1_0)]]\n"
     ]
    }
   ],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss,correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%X_train.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[i:i+batch_size].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    return total_loss,total_correct\n",
    "\n",
    "X_train = train_data\n",
    "y_train = train_labels\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Training')\n",
    "        run_model(sess,xy_output,mean_loss,X_train,y_train,1,3,3,train_step,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The below is discontinued code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 144, 144, 3, 4)\n",
      "(24, 2)\n",
      "(3, 144, 144, 3, 4)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# We are testing the Gazelle CNN on the *tiny* dataset right now:\n",
    "# train_data_tiny, train_labels_tiny, eval_data_tiny, eval_labels_tiny\n",
    "# Load training and eval data from GazeCapture dataset\n",
    "'''\n",
    "Discontinued\n",
    "'''\n",
    "CNN_DATA_ROOT = \"toy_CNN_data/\"\n",
    "train_data = pickle.load(open(CNN_DATA_ROOT + 'train_data_tiny.pkl', 'rb'))\n",
    "train_labels = pickle.load(open(CNN_DATA_ROOT + 'train_labels_tiny.pkl', 'rb'))\n",
    "eval_data = pickle.load(open(CNN_DATA_ROOT + 'eval_data_tiny.pkl', 'rb'))\n",
    "eval_labels = pickle.load(open(CNN_DATA_ROOT + 'eval_labels_tiny.pkl', 'rb'))\n",
    "\n",
    "print (train_data.shape)\n",
    "print (train_labels.shape)\n",
    "print (eval_data.shape)\n",
    "print (eval_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-62d686d17fd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mypath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatapath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'XYArray'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#print \"new X: \", np.load(Xpath).shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First populate X_train and y_train with the first data chunks\n",
    "firstdatapath = datapath + \"/\" + 'data1.npy'\n",
    "firstXYpath = datapath + \"/\" + 'XYArray1.npy'\n",
    "X_train = np.load(firstdatapath)\n",
    "y_train = np.load(firstXYpath)\n",
    "\n",
    "# Concatenate all the other data\n",
    "for i in xrange(len(onlyfiles) / 2 + 1):\n",
    "    if i is 0:\n",
    "        continue\n",
    "    Xpath = datapath + \"/\" + 'data' + str(i) + '.npy'\n",
    "    ypath = datapath + \"/\" + 'XYArray' + str(i) + '.npy'\n",
    "    #print \"new X: \", np.load(Xpath).shape\n",
    "    X_train = np.concatenate((X_train, np.load(Xpath)))\n",
    "    y_train = np.concatenate((y_train, np.load(ypath)))\n",
    "\n",
    "print \"X_train: \", X_train.shape\n",
    "print \"y_train: \", y_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
